{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import glob                               #can be used to find the target files\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib                   # to read and write neuron imaging data \n",
    "import numpy as np                        # for matrix calculating\n",
    "import subprocess\n",
    "from PIL import Image \n",
    "import os,shutil\n",
    "\n",
    "from scipy import signal\n",
    "from skimage import color, img_as_ubyte, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_script = 'results_script1'\n",
    "if not os.path.exists(file_script):\n",
    "    os.mkdir(file_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy('/home/zhiwei/Desktop/semester-projects/original_file/3000/BVECTOR.scheme','results_script1')\n",
    "shutil.copy('/home/zhiwei/Desktop/semester-projects/original_file/3000/fsltensor_FA.nii.gz','results_script1')\n",
    "shutil.copy('/home/zhiwei/Desktop/semester-projects/original_file/3000/fsltensor_V3.nii.gz','results_script1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD = 'shutil.copy(“fsltensor_V1.nii.gz”,”results_script1”)'\n",
    "subprocess.call(CMD,shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd results_script1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate original tractography and get fib_original, hdr_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nib.load('fsltensor_FA.nii.gz')\n",
    "d=np.ones(data.get_data().shape)\n",
    "img=nib.Nifti1Image(d, data.affine)\n",
    "nib.save(img,'mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD='tckgen fsltensor_V3.nii.gz origin0.015.tck -algorithm FACT -seed_image mask.nii -mask mask.nii -select 500 -step 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD = 'TractConverter.py -i origin0.015.tck -o origin0.015.trk -a fsltensor_FA.nii.gz'\n",
    "subprocess.call(CMD,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_original,hdr_original=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/origin0.015.trk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate synthetic CLARITY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD='tckmap origin0.015.tck syn_CLARITY.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## calculate structure tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doggen(sigma=None, X=None, Y=None, Z=None):\n",
    "    halfsize = np.ceil(3 * np.max(sigma))       #3*the maximum number of sequence sigma, ceil: shangxian\n",
    "    x = np.arange(-halfsize,halfsize+1)         # sequence from -halfsize to halfsize+1\n",
    "\n",
    "    if len(sigma) == 1:\n",
    "        if X is None:\n",
    "            X = x\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) )\n",
    "    if len(sigma) == 2:\n",
    "        if X is None or Y is None:\n",
    "            [X,Y] =np.meshgrid(x,x)\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) ) * np.exp( (-1)*np.power(Y,2)/(2 * np.power(sigma[1],2)) )\n",
    "    if len(sigma) == 3:\n",
    "        if X is None or Y is None or Z is None:\n",
    "            [X,Y,Z] =np.meshgrid(x,x,x)\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) ) * np.exp( (-1)*np.power(Y,2)/(2 * np.power(sigma[1],2)) ) * np.exp( (-1)*np.power(Z,2)/(2 * np.power(sigma[2],2)))\n",
    "    if len(sigma) > 3:\n",
    "        print ('Only support up to dimension 3')\n",
    "    \n",
    "    return k /np.sum(np.abs(k))\n",
    "\n",
    "def gradCompute(img, dogsigma):\n",
    "    dogkercc = doggen([dogsigma, dogsigma, dogsigma])\n",
    "    dogkerrr = np.transpose( dogkercc, (1, 0, 2) )\n",
    "    dogkerzz = np.transpose( dogkercc, (0, 2, 1) )\n",
    "\n",
    "    gcc = signal.convolve(img, dogkercc, mode = 'valid')\n",
    "    grr = signal.convolve(img, dogkerrr, mode = 'valid')\n",
    "    gzz = signal.convolve(img, dogkerzz, mode = 'valid')\n",
    "\n",
    "    # Gradient products\n",
    "    gp = type('', (), {})()\n",
    "    gp.gprrrr = grr * grr\n",
    "    gp.gprrcc = grr * gcc\n",
    "    gp.gprrzz = grr * gzz\n",
    "    gp.gpcccc = gcc * gcc\n",
    "    gp.gpcczz = gcc * gzz\n",
    "    gp.gpzzzz = gzz * gzz\n",
    "\n",
    "    # Gradient amplitude\n",
    "    ga = np.sqrt(gp.gprrrr + gp.gpcccc + gp.gpzzzz)\n",
    "\n",
    "    return ga, gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the optimal patch_size to retrieve the exact size of CLARITY as the originally synthetic one!! do not change this anymore!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_stack = nib.load('syn_CLARITY.nii.gz')\n",
    "imgstack = img_stack.get_fdata()/255.0\n",
    "\n",
    "\n",
    "# select sigma\n",
    "dogsigma = [0.6]\n",
    "vox_size = [15, 15, 15] #um\n",
    "#define the voxel dimension to apply tensor\n",
    "voxel_dim = np.array([patch_size,patch_size,patch_size]) # x,y,z in voxel dimension\n",
    "volume_dim = (np.array(imgstack.shape)/voxel_dim).astype(np.int) # in voxel dimesion: removed voxel at the border\n",
    "\n",
    "fsl_tensor = np.zeros((volume_dim[0], volume_dim[1], volume_dim[2], 6))\n",
    "for x in range (0,volume_dim[0]):\n",
    "    for y in range (0,volume_dim[1]):\n",
    "        for z in range (0, volume_dim[2]):\n",
    "            [ga,gp] = gradCompute(imgstack[int(x*voxel_dim[0]):int((x+1)*voxel_dim[0]), int(y*voxel_dim[1]):int((y+1)*voxel_dim[1]), int(z*voxel_dim[2]):int((z+1)*voxel_dim[2])], dogsigma)\n",
    "\n",
    "            lowthreh = np.percentile(ga.reshape(-1), 20)\n",
    "            highthreh = np.percentile(ga.reshape(-1), 80)\n",
    "\n",
    "            mask = np.ones(ga.shape)\n",
    "            mask[ga  < lowthreh] = 0\n",
    "            mask[ga  > highthreh] = 0\n",
    "\n",
    "            gprrrr = np.sum(gp.gprrrr[mask==1])\n",
    "            gprrcc = np.sum(gp.gprrcc[mask==1])\n",
    "            gprrzz = np.sum(gp.gprrzz[mask==1])\n",
    "            gpcccc = np.sum(gp.gpcccc[mask==1])\n",
    "            gpcczz = np.sum(gp.gpcczz[mask==1])\n",
    "            gpzzzz = np.sum(gp.gpzzzz[mask==1])\n",
    "\n",
    "            fsl_tensor[x,y,z] = np.array([[gprrrr, gprrcc, gprrzz,gpcccc, gpcczz, gpzzzz]])\n",
    "affine = np.eye(4)\n",
    "affine[0,0]=vox_size[0]*voxel_dim[0]*0.001\n",
    "affine[1,1]=vox_size[1]*voxel_dim[1]*0.001\n",
    "affine[2,2]=vox_size[2]*voxel_dim[2]*0.001\n",
    "img_fsl_tensor = nib.Nifti1Image(fsl_tensor, affine)\n",
    "nib.save(img_fsl_tensor, 'fsltensor_ftrial.nii.gz')\n",
    "CMD='fsl5.0-fslmaths fsltensor_ftrial.nii.gz -tensor_decomp fsltensor_ftrial'\n",
    "subprocess.call(CMD, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the mask for subsequent tractography generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nib.load('fsltensor_ftrial_FA.nii.gz')\n",
    "d=np.ones(data.get_data().shape)\n",
    "img=nib.Nifti1Image(d, data.affine)\n",
    "nib.save(img,'mask_syn.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate the tractography and subsequent CLARITY based on the synthetic CLARITY images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD='tckgen fsltensor_ftrial_V3.nii.gz before0.015.tck -algorithm FACT -seed_image mask_syn.nii -mask mask_syn.nii -select 100000 -step 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD = 'TractConverter.py -i before0.015.tck -o before0.015.trk -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_before,hdr_before=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/before0.015.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in range(len(fib_original)):\n",
    "    fib_before.append(fib_original[items])\n",
    "nib.trackvis.write('fibers_before_all.trk',fib_before,hdr_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD = 'TractConverter.py -i fibers_before_all.trk -o fibers_before_all.tck -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD='tckmap fibers_before_all.tck syn_CLARITY_before.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for comparison of two tractography on a voxel base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compClarity(volume1,volume2):\n",
    "    error = 0.0\n",
    "    for x in range(volume1.shape[0]):\n",
    "        for y in range(volume1.shape[1]):\n",
    "            for z in range(volume1.shape[2]):\n",
    "                error = error + np.abs(volume1[x,y,z]-volume2[x,y,z])\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply COMMIT to the generated tractography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_commit = '/home/zhiwei/Desktop/semester-projects/results_script1/COMMIT'\n",
    "path = '/home/zhiwei/Desktop/semester-projects/results_script1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_file_before = '/home/zhiwei/Desktop/semester-projects/results_script1/fibers_before_all.trk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commit import trk2dictionary\n",
    "trk2dictionary.run(filename_trk   = trk_file_before ,path_out= path_commit )\n",
    "import commit\n",
    "commit.core.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit=commit.Evaluation('.','results_script1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit.load_data('/home/zhiwei/Desktop/semester-projects/results_script1/syn_CLARITY.nii.gz','/home/zhiwei/Desktop/semester-projects/results_script1/BVECTOR.scheme')\n",
    "mit.set_model('VolumeFractions')\n",
    "hasISO=False\n",
    "mit.model.set(hasISO)\n",
    "mit.generate_kernels(regenerate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit.load_kernels()\n",
    "mit.load_dictionary(path_commit)\n",
    "mit.set_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit.build_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit.fit(max_iter = 100000000)\n",
    "## mit.fit(tol_fun = 1e-7, max_iter = 100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mit.save_results(save_coeff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_file = os.path.join(path_commit,'dictionary_TRK_fibers.trk')\n",
    "fib_tmp,trk_hdr_tmp=nib.trackvis.read(trk_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate tractography after applying COMMIT with weight > 0, and get fib_after,hdr_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/zhiwei/Desktop/semester-projects/results_script1/COMMIT/Results_VolumeFractions/xic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "data = f.read().splitlines()\n",
    "data = map(eval,data)\n",
    "max_index_list = map(data.index, heapq.nlargest(500,data))\n",
    "\n",
    "#j=0\n",
    "#for items in range(len(fib_tmp)-1,-1,-1):\n",
    "#    if data[j] == 0:\n",
    "#        del fib_tmp[items]\n",
    "#    j=j+1\n",
    "#nib.trackvis.write('fibers_after.trk',fib_tmp,trk_hdr_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for items in range(len(fib_tmp)-1,-1,-1):\n",
    "    if items not in max_index_list:\n",
    "        del fib_tmp[items]\n",
    "nib.trackvis.write('fibers_after.trk',fib_tmp,trk_hdr_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_after,hdr_after=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/fibers_after.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD = 'TractConverter.py -i fibers_after.trk -o fibers_after.tck -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMD='tckmap fibers_after.tck syn_CLARITY_after.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample fibers(before/after) to the original one, take mean distance and std as measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample the fibers and get tracks_before, tracks_after, tracks_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.metrics import downsample\n",
    "import random\n",
    "tracks_after = [downsample(fib_after[i][0],7) for i in range(len(fib_after))]\n",
    "tracks_original = [downsample(fib_original[i][0],7) for i in range(len(fib_original))]\n",
    "## generate a random list to get equal number of fibers from fib before COMMIT\n",
    "list = range(len(fib_before))\n",
    "slice1 = random.sample(list, len(fib_after))\n",
    "tracks_before1 = [downsample(fib_before[i][0],7) for i in slice1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.bundles import bundles_distances_mdf\n",
    "DM_before1 = bundles_distances_mdf(tracks_before1, tracks_original)\n",
    "minD_before1 = [min(DM_before1[i,:]) for i in range(len(DM_before1))]\n",
    "DM_after = bundles_distances_mdf(tracks_after, tracks_original)\n",
    "minD_after = [min(DM_after[i,:]) for i in range(len(DM_after))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare tracks_after and tracks_before with tracks_original with mean distance and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD_before= np.mean(minD_before1)\n",
    "stdD_before= np.std(minD_before1)\n",
    "\n",
    "meanD_after= np.mean(minD_after)\n",
    "stdD_after= np.std(minD_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare on a voxel level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original resolution -- 0.015mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for items in range(len(fib_before)-1,-1,-1):\n",
    "    if items not in slice1:\n",
    "        del fib_before[items]\n",
    "    j=j+1\n",
    "nib.trackvis.write('fibers_before.trk',fib_before,hdr_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_before,hdr_before=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/fibers_before.trk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD = 'TractConverter.py -i fibers_before.trk -o fibers_before.tck -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD='tckmap fibers_before.tck syn_CLARITY_random.nii.gz -vox 0.015' \n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_original = nib.load('syn_CLARITY.nii.gz')\n",
    "data_before = nib.load('syn_CLARITY_random.nii.gz')\n",
    "data_after = nib.load('syn_CLARITY_after.nii.gz')\n",
    "original = data_original.get_fdata()\n",
    "random = data_before.get_fdata()\n",
    "after = data_after.get_fdata()\n",
    "\n",
    "## normalization\n",
    "sum_original = sum(sum(sum(data_original.get_fdata())))\n",
    "sum_before = sum(sum(sum(data_before.get_fdata())))\n",
    "sum_after = sum(sum(sum(data_after.get_fdata())))\n",
    "volume_original = data_original.get_fdata()/sum_original\n",
    "volume_before = data_before.get_fdata()/sum_before\n",
    "volume_after = data_after.get_fdata()/sum_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation measure to conduct grey level matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "center_original = (original-sum_original/(191*178*39)).flatten()\n",
    "center_before = (random - sum_before/(191*178*39)).flatten()\n",
    "center_after = (after - sum_after/(191*178*39)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "module_original = np.sqrt(np.dot(center_original,center_original))\n",
    "module_before = np.sqrt(np.dot(center_before,center_before))\n",
    "module_after = np.sqrt(np.dot(center_after,center_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_coef = np.dot(center_original.flatten(),center_before.flatten())/(module_original*module_before)\n",
    "COMMIT_coef = np.dot(center_original.flatten(),center_after.flatten())/(module_original*module_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(random_coef)\n",
    "print(COMMIT_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "square_error_before = compClarity(volume_before, volume_original)\n",
    "square_error_after = compClarity(volume_after, volume_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(square_error_before)\n",
    "print(square_error_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change the resolution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resolution based on mean distance after COMMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "CMD='tckmap origin0.015.tck syn_CLARITY_COMMIT_res.nii.gz -vox 0.195' \n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD='tckmap fibers_after.tck syn_CLARITY_after_COMMIT_res.nii.gz -vox 0.195'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD='tckmap fibers_before.tck syn_CLARITY_random_COMMIT_res.nii.gz -vox 0.195'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_original_COMMIT_res = nib.load('syn_CLARITY_COMMIT_res.nii.gz')\n",
    "data_before_COMMIT_res = nib.load('syn_CLARITY_random_COMMIT_res.nii.gz')\n",
    "data_after_COMMIT_res = nib.load('syn_CLARITY_after_COMMIT_res.nii.gz')\n",
    "## normalization\n",
    "sum_original_COMMIT_res = sum(sum(sum(data_original_COMMIT_res.get_fdata())))\n",
    "sum_before_COMMIT_res = sum(sum(sum(data_before_COMMIT_res.get_fdata())))\n",
    "sum_after_COMMIT_res = sum(sum(sum(data_after_COMMIT_res.get_fdata())))\n",
    "volume_original_COMMIT_res = data_original_COMMIT_res.get_fdata()/sum_original_COMMIT_res\n",
    "volume_before_COMMIT_res = data_before_COMMIT_res.get_fdata()/sum_before_COMMIT_res\n",
    "volume_after_COMMIT_res = data_after_COMMIT_res.get_fdata()/sum_after_COMMIT_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "square_error_before_COMMIT_res = compClarity(volume_before_COMMIT_res, volume_original_COMMIT_res)\n",
    "square_error_after_COMMIT_res = compClarity(volume_after_COMMIT_res, volume_original_COMMIT_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare on a voxel level - binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original resolution -- 0.015mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def binarize(volume):\n",
    "    volume_prime = np.zeros([len(volume),len(volume[1]),len(volume[1][1])])\n",
    "    for x in range(len(volume)):\n",
    "        for y in range(len(volume[1])):\n",
    "            for z in range(len(volume[1][1])):\n",
    "                if volume[x,y,z]!=0:\n",
    "                    volume_prime[x,y,z]=1\n",
    "    return volume_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volume_Original = binarize(volume_original)\n",
    "Volume_Before = binarize(volume_before)\n",
    "Volume_After = binarize(volume_after)\n",
    "error_before = compClarity(Volume_Before, Volume_Original)\n",
    "error_after = compClarity(Volume_After, Volume_Original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(error_before)\n",
    "print(error_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## change the resolution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMIT resolution 0.186"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volume_Original_COMMIT_res = binarize(volume_original_COMMIT_res)\n",
    "Volume_Before_COMMIT_res = binarize(volume_before_COMMIT_res)\n",
    "Volume_After_COMMIT_res = binarize(volume_after_COMMIT_res)\n",
    "error_before_COMMIT_res = compClarity(Volume_Before_COMMIT_res, Volume_Original_COMMIT_res)\n",
    "error_after_COMMIT_res = compClarity(Volume_After_COMMIT_res, Volume_Original_COMMIT_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_RANDOM_COMMIT.txt','a')  \n",
    "f.write(str(meanD_before)+', ')\n",
    "f.write(str(meanD_after)+', ')\n",
    "f.close()\n",
    "\n",
    "f = open('stdD_RANDOM_COMMIT.txt','a') \n",
    "f.write(str(stdD_before)+', ')\n",
    "f.write(str(stdD_after)+', ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open('VOXEL_B_random_COMMIT.txt','a')\n",
    "f.write(str(error_before)+', ')\n",
    "f.write(str(error_after)+', ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open('VOXEL_NB_random_commit.txt','a')\n",
    "f.write(str(square_error_before)+', ')\n",
    "f.write(str(square_error_after)+', ')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open('coef_random_COMMIT.txt','a')\n",
    "f.write(str(random_coef)+', ')\n",
    "f.write(str(COMMIT_coef)+', ')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level_COMMIT_res - BINARIZATION:')\n",
    "f.write('\\nerror random: ' + str(error_before_COMMIT_res))\n",
    "f.write('\\nerror COMMIT: ' + str(error_after_COMMIT_res)) \n",
    "f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level_COMMIT_res- non-BINARIZATION:')\n",
    "f.write('\\nsquare error random: ' + str(square_error_before_COMMIT_res))\n",
    "f.write('\\nsquare error COMMIT: ' + str(square_error_after_COMMIT_res)) \n",
    "f.write('\\n\\n\\n\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('results_script1','5_PERCENTER_%d'%order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

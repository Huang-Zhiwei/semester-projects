{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import glob                               #can be used to find the target files\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib                   # to read and write neuron imaging data \n",
    "import numpy as np                        # for matrix calculating\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "import os,shutil\n",
    "\n",
    "from scipy import signal\n",
    "from skimage import color, img_as_ubyte, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_script = 'results_script1'\n",
    "if not os.path.exists(file_script):\n",
    "    os.mkdir(file_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CMD = 'shutil.copy(“fsltensor_V1.nii.gz”,”results_script1”)'\n",
    "subprocess.call(CMD,shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhiwei/Desktop/semester-projects/results_script1\n"
     ]
    }
   ],
   "source": [
    "cd results_script1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate original tractography and get fib_original, hdr_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nib.load('fsltensor_FA.nii.gz')\n",
    "d=np.ones(data.get_data().shape)\n",
    "img=nib.Nifti1Image(d, data.affine)\n",
    "nib.save(img,'mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckgen fsltensor_V3.nii.gz origin0.015.tck -algorithm FACT -seed_image mask.nii -mask mask.nii -select 3000 -step 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD = 'TractConverter.py -i origin0.015.tck -o origin0.015.trk -a fsltensor_FA.nii.gz'\n",
    "subprocess.call(CMD,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_original,hdr_original=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/origin0.015.trk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate synthetic CLARITY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap origin0.015.tck syn_CLARITY.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## calculate structure tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doggen(sigma=None, X=None, Y=None, Z=None):\n",
    "    halfsize = np.ceil(3 * np.max(sigma))       #3*the maximum number of sequence sigma, ceil: shangxian\n",
    "    x = np.arange(-halfsize,halfsize+1)         # sequence from -halfsize to halfsize+1\n",
    "\n",
    "    if len(sigma) == 1:\n",
    "        if X is None:\n",
    "            X = x\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) )\n",
    "    if len(sigma) == 2:\n",
    "        if X is None or Y is None:\n",
    "            [X,Y] =np.meshgrid(x,x)\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) ) * np.exp( (-1)*np.power(Y,2)/(2 * np.power(sigma[1],2)) )\n",
    "    if len(sigma) == 3:\n",
    "        if X is None or Y is None or Z is None:\n",
    "            [X,Y,Z] =np.meshgrid(x,x,x)\n",
    "        k = (-1)*X * np.exp( (-1)*np.power(X,2)/(2 * np.power(sigma[0],2)) ) * np.exp( (-1)*np.power(Y,2)/(2 * np.power(sigma[1],2)) ) * np.exp( (-1)*np.power(Z,2)/(2 * np.power(sigma[2],2)))\n",
    "    if len(sigma) > 3:\n",
    "        print ('Only support up to dimension 3')\n",
    "    \n",
    "    return k /np.sum(np.abs(k))\n",
    "\n",
    "def gradCompute(img, dogsigma):\n",
    "    dogkercc = doggen([dogsigma, dogsigma, dogsigma])\n",
    "    dogkerrr = np.transpose( dogkercc, (1, 0, 2) )\n",
    "    dogkerzz = np.transpose( dogkercc, (0, 2, 1) )\n",
    "\n",
    "    gcc = signal.convolve(img, dogkercc, mode = 'valid')\n",
    "    grr = signal.convolve(img, dogkerrr, mode = 'valid')\n",
    "    gzz = signal.convolve(img, dogkerzz, mode = 'valid')\n",
    "\n",
    "    # Gradient products\n",
    "    gp = type('', (), {})()\n",
    "    gp.gprrrr = grr * grr\n",
    "    gp.gprrcc = grr * gcc\n",
    "    gp.gprrzz = grr * gzz\n",
    "    gp.gpcccc = gcc * gcc\n",
    "    gp.gpcczz = gcc * gzz\n",
    "    gp.gpzzzz = gzz * gzz\n",
    "\n",
    "    # Gradient amplitude\n",
    "    ga = np.sqrt(gp.gprrrr + gp.gpcccc + gp.gpzzzz)\n",
    "\n",
    "    return ga, gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the optimal patch_size to retrieve the exact size of CLARITY as the originally synthetic one!! do not change this anymore!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiwei/.local/lib/python2.7/site-packages/scipy/signal/signaltools.py:491: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_stack = nib.load('syn_CLARITY.nii.gz')\n",
    "imgstack = img_stack.get_fdata()/255.0\n",
    "\n",
    "\n",
    "# select sigma\n",
    "dogsigma = [0.6]\n",
    "vox_size = [15, 15, 15] #um\n",
    "#define the voxel dimension to apply tensor\n",
    "voxel_dim = np.array([patch_size,patch_size,patch_size]) # x,y,z in voxel dimension\n",
    "volume_dim = (np.array(imgstack.shape)/voxel_dim).astype(np.int) # in voxel dimesion: removed voxel at the border\n",
    "\n",
    "fsl_tensor = np.zeros((volume_dim[0], volume_dim[1], volume_dim[2], 6))\n",
    "for x in range (0,volume_dim[0]):\n",
    "    for y in range (0,volume_dim[1]):\n",
    "        for z in range (0, volume_dim[2]):\n",
    "            [ga,gp] = gradCompute(imgstack[int(x*voxel_dim[0]):int((x+1)*voxel_dim[0]), int(y*voxel_dim[1]):int((y+1)*voxel_dim[1]), int(z*voxel_dim[2]):int((z+1)*voxel_dim[2])], dogsigma)\n",
    "\n",
    "            lowthreh = np.percentile(ga.reshape(-1), 20)\n",
    "            highthreh = np.percentile(ga.reshape(-1), 80)\n",
    "\n",
    "            mask = np.ones(ga.shape)\n",
    "            mask[ga  < lowthreh] = 0\n",
    "            mask[ga  > highthreh] = 0\n",
    "\n",
    "            gprrrr = np.sum(gp.gprrrr[mask==1])\n",
    "            gprrcc = np.sum(gp.gprrcc[mask==1])\n",
    "            gprrzz = np.sum(gp.gprrzz[mask==1])\n",
    "            gpcccc = np.sum(gp.gpcccc[mask==1])\n",
    "            gpcczz = np.sum(gp.gpcczz[mask==1])\n",
    "            gpzzzz = np.sum(gp.gpzzzz[mask==1])\n",
    "\n",
    "            fsl_tensor[x,y,z] = np.array([[gprrrr, gprrcc, gprrzz,gpcccc, gpcczz, gpzzzz]])\n",
    "affine = np.eye(4)\n",
    "affine[0,0]=vox_size[0]*voxel_dim[0]*0.001\n",
    "affine[1,1]=vox_size[1]*voxel_dim[1]*0.001\n",
    "affine[2,2]=vox_size[2]*voxel_dim[2]*0.001\n",
    "img_fsl_tensor = nib.Nifti1Image(fsl_tensor, affine)\n",
    "nib.save(img_fsl_tensor, 'fsltensor_ftrial.nii.gz')\n",
    "CMD='fsl5.0-fslmaths fsltensor_ftrial.nii.gz -tensor_decomp fsltensor_ftrial'\n",
    "subprocess.call(CMD, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the mask for subsequent tractography generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nib.load('fsltensor_ftrial_FA.nii.gz')\n",
    "d=np.ones(data.get_data().shape)\n",
    "img=nib.Nifti1Image(d, data.affine)\n",
    "nib.save(img,'mask_syn.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate the tractography and subsequent CLARITY based on the synthetic CLARITY images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckgen fsltensor_ftrial_V3.nii.gz before0.015.tck -algorithm FACT -seed_image mask_syn.nii -mask mask_syn.nii -select 100000 -step 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD = 'TractConverter.py -i before0.015.tck -o before0.015.trk -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_before,hdr_before=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/before0.015.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap before0.015.tck syn_CLARITY_before.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for comparison of two tractography on a voxel base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compClarity(volume1,volume2):\n",
    "    square_error = 0.0\n",
    "    for x in range(volume1.shape[0]):\n",
    "        for y in range(volume1.shape[1]):\n",
    "            for z in range(volume1.shape[2]):\n",
    "                square_error = square_error + np.square(volume1[x,y,z]-volume2[x,y,z])\n",
    "    return square_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply COMMIT to the generated tractography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_commit = '/home/zhiwei/Desktop/semester-projects/results_script1/COMMIT'\n",
    "path = '/home/zhiwei/Desktop/semester-projects/results_script1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_file_before = '/home/zhiwei/Desktop/semester-projects/results_script1/before0.015.trk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Creating the dictionary from tractogram:\n",
      "\t* Segment position = COMPUTE INTERSECTIONS\n",
      "\t* Fiber shift X    = 0.000 (voxel-size units)\n",
      "\t* Fiber shift Y    = 0.000 (voxel-size units)\n",
      "\t* Fiber shift Z    = 0.000 (voxel-size units)\n",
      "\t* Points to skip   = 0\n",
      "\t* Min segment len  = 1.00e-03\n",
      "\t* Do not blur fibers\n",
      "\t* Loading data:\n",
      "\t\t* tractogram\n",
      "\t\t\t- 28 x 26 x 5\n",
      "\t\t\t- 0.0990 x 0.0990 x 0.0990\n",
      "\t\t\t- 100000 fibers\n",
      "\t\t* no mask specified to filter IC compartments\n",
      "\t\t* no dataset specified for EC compartments\n",
      "\t\t* output written to \"/home/zhiwei/Desktop/semester-projects/results_script1/COMMIT\"\n",
      "\t* Generate tractogram matching the dictionary: \n",
      "\t  [ 99781 fibers kept ]\n",
      "   [ 12.1 seconds ]\n"
     ]
    }
   ],
   "source": [
    "from commit import trk2dictionary\n",
    "trk2dictionary.run(filename_trk   = trk_file_before ,path_out= path_commit )\n",
    "import commit\n",
    "commit.core.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit=commit.Evaluation('.','results_script1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Loading data:\n",
      "\t* DWI signal...\n",
      "\t\t- dim    = 191 x 178 x 39 x 1\n",
      "\t\t- pixdim = 0.015 x 0.015 x 0.015\n",
      "\t* Acquisition scheme...\n",
      "\t\t- 1 samples, 1 shells\n",
      "\t\t- 0 @ b=0 , 1 @ b=1000.0\n",
      "   [ 0.0 seconds ]\n",
      "\n",
      "-> Preprocessing:\n",
      "\t* There are no b0 volume(s) for normalization... [ min=0.00,  mean=0.25, max=28.00 ]\n",
      "   [ 0.0 seconds ]\n",
      "\n",
      "-> Simulating with \"Volume fractions\" model:\n",
      "   [ 0.0 seconds ]\n"
     ]
    }
   ],
   "source": [
    "mit.load_data('/home/zhiwei/Desktop/semester-projects/results_script1/syn_CLARITY.nii.gz','/home/zhiwei/Desktop/semester-projects/results_script1/BVECTOR.scheme')\n",
    "mit.set_model('VolumeFractions')\n",
    "hasISO=False\n",
    "mit.model.set(hasISO)\n",
    "mit.generate_kernels(regenerate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Resampling LUT for subject \"results_script1\":\n",
      "\t* Keeping all b0 volume(s)... [ OK ]\n",
      "\t* Normalizing... [ OK ]\n",
      "   [ 0.1 seconds ]\n",
      "\n",
      "-> Loading the dictionary:\n",
      "\t* segments from the tracts... [ 99781 fibers and 4812915 segments ]\n",
      "\t* segments from the peaks...  [ 0 segments ]\n",
      "\t* isotropic contributions...  [ 3580 voxels ]\n",
      "\t* post-processing...          [ OK ]\n",
      "   [ 1.2 seconds ]\n",
      "\n",
      "-> Distributing workload to different threads:\n",
      "\t* number of threads : 1\n",
      "\t* A operator...  [ OK ]\n",
      "\t* A' operator... [ OK ]\n",
      "   [ 0.0 seconds ]\n"
     ]
    }
   ],
   "source": [
    "mit.load_kernels()\n",
    "mit.load_dictionary(path_commit)\n",
    "mit.set_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Building linear operator A:\n",
      "   [ 3.3 seconds ]\n"
     ]
    }
   ],
   "source": [
    "mit.build_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Fit model\n",
      "\n",
      "      |     ||Ax-y||     |  Cost function    Abs error      Rel error    |     Abs x          Rel x\n",
      "------|------------------|-----------------------------------------------|------------------------------\n",
      "   1  |   3.2653759e+03  |  5.3313400e+06  3.6294864e+07  6.8078314e+00  |  1.9188958e+02  1.1041560e+00\n",
      "   2  |   2.1698470e+03  |  2.3541180e+06  2.9772220e+06  1.2646868e+00  |  5.1131140e+01  3.8653859e-01\n",
      "   3  |   1.4342165e+03  |  1.0284885e+06  1.3256295e+06  1.2889103e+00  |  3.8427962e+01  3.7823379e-01\n",
      "   4  |   9.5830984e+02  |  4.5917888e+05  5.6930965e+05  1.2398429e+00  |  2.8214561e+01  3.5385482e-01\n",
      "   5  |   6.6138736e+02  |  2.1871662e+05  2.4046226e+05  1.0994238e+00  |  2.0333924e+01  3.1642346e-01\n",
      "   6  |   4.7345064e+02  |  1.1207775e+05  1.0663887e+05  9.5147220e-01  |  1.4949392e+01  2.8182975e-01\n",
      "   7  |   3.4950447e+02  |  6.1076688e+04  5.1001065e+04  8.3503325e-01  |  1.1297714e+01  2.5277341e-01\n",
      "   8  |   2.6526835e+02  |  3.5183649e+04  2.5893039e+04  7.3593954e-01  |  8.7076398e+00  2.2708220e-01\n",
      "   9  |   2.0675574e+02  |  2.1373969e+04  1.3809681e+04  6.4609810e-01  |  6.8090204e+00  2.0377025e-01\n",
      "  10  |   1.6521209e+02  |  1.3647517e+04  7.7264520e+03  5.6614343e-01  |  5.4121369e+00  1.8347206e-01\n",
      "  11  |   1.3480598e+02  |  9.0863267e+03  4.5611900e+03  5.0198393e-01  |  4.3920189e+00  1.6686912e-01\n",
      "  12  |   1.1191311e+02  |  6.2622716e+03  2.8240551e+03  4.5096337e-01  |  3.6397535e+00  1.5360175e-01\n",
      "  13  |   9.4330634e+01  |  4.4491343e+03  1.8131374e+03  4.0752588e-01  |  3.0558742e+00  1.4212967e-01\n",
      "  14  |   8.0594573e+01  |  3.2477426e+03  1.2013917e+03  3.6991591e-01  |  2.5977458e+00  1.3225330e-01\n",
      "  15  |   6.9714878e+01  |  2.4300821e+03  8.1766048e+02  3.3647442e-01  |  2.2262032e+00  1.2331471e-01\n",
      "  16  |   6.0970635e+01  |  1.8587092e+03  5.7137294e+02  3.0740309e-01  |  1.9295697e+00  1.1567221e-01\n",
      "  17  |   5.3901440e+01  |  1.4526826e+03  4.0602654e+02  2.7950120e-01  |  1.6793615e+00  1.0842972e-01\n",
      "  18  |   4.8139044e+01  |  1.1586838e+03  2.9399886e+02  2.5373520e-01  |  1.4755437e+00  1.0217608e-01\n",
      "  19  |   4.3359262e+01  |  9.4001280e+02  2.1867098e+02  2.3262554e-01  |  1.3113854e+00  9.7018219e-02\n",
      "  20  |   3.9388646e+01  |  7.7573272e+02  1.6428008e+02  2.1177408e-01  |  1.1663514e+00  9.1865718e-02\n",
      "  21  |   3.6052826e+01  |  6.4990313e+02  1.2582959e+02  1.9361284e-01  |  1.0481118e+00  8.7608291e-02\n",
      "  22  |   3.3237934e+01  |  5.5238011e+02  9.7523014e+01  1.7655055e-01  |  9.4517712e-01  8.3596071e-02\n",
      "  23  |   3.0841818e+01  |  4.7560886e+02  7.6771256e+01  1.6141679e-01  |  8.5698415e-01  7.9981888e-02\n",
      "  24  |   2.8798206e+01  |  4.1466833e+02  6.0940531e+01  1.4696211e-01  |  7.7944875e-01  7.6569084e-02\n",
      "  25  |   2.7039055e+01  |  3.6555524e+02  4.9113087e+01  1.3435203e-01  |  7.1261927e-01  7.3509651e-02\n",
      "  26  |   2.5531403e+01  |  3.2592627e+02  3.9628972e+01  1.2158876e-01  |  6.5020271e-01  7.0274618e-02\n",
      "  27  |   2.4241549e+01  |  2.9382636e+02  3.2099909e+01  1.0924789e-01  |  5.9574925e-01  6.7328960e-02\n",
      "  28  |   2.3133718e+01  |  2.6758446e+02  2.6241900e+01  9.8069599e-02  |  5.4473295e-01  6.4255556e-02\n",
      "  29  |   2.2175081e+01  |  2.4586711e+02  2.1717351e+01  8.8329631e-02  |  5.0313899e-01  6.1842044e-02\n",
      "  30  |   2.1346839e+01  |  2.2784377e+02  1.8023338e+01  7.9103934e-02  |  4.6407148e-01  5.9344630e-02\n",
      "  31  |   2.0629760e+01  |  2.1279350e+02  1.5050273e+01  7.0727131e-02  |  4.3140140e-01  5.7315482e-02\n",
      "  32  |   1.9998228e+01  |  1.9996456e+02  1.2828940e+01  6.4156072e-02  |  4.0478348e-01  5.5799628e-02\n",
      "  33  |   1.9447659e+01  |  1.8910573e+02  1.0858829e+01  5.7422001e-02  |  3.7628340e-01  5.3751996e-02\n",
      "  34  |   1.8960357e+01  |  1.7974758e+02  9.3581508e+00  5.2062737e-02  |  3.5353269e-01  5.2272209e-02\n",
      "  35  |   1.8528986e+01  |  1.7166167e+02  8.0859055e+00  4.7103733e-02  |  3.3239160e-01  5.0812272e-02\n",
      "  36  |   1.8139634e+01  |  1.6452315e+02  7.1385151e+00  4.3389121e-02  |  3.1560150e-01  4.9826486e-02\n",
      "  37  |   1.7788679e+01  |  1.5821855e+02  6.3046066e+00  3.9847456e-02  |  3.0022308e-01  4.8898197e-02\n",
      "  38  |   1.7472953e+01  |  1.5265204e+02  5.5665115e+00  3.6465360e-02  |  2.8465192e-01  4.7776357e-02\n",
      "  39  |   1.7188610e+01  |  1.4772416e+02  4.9278801e+00  3.3358661e-02  |  2.7091128e-01  4.6806439e-02\n",
      "  40  |   1.6931637e+01  |  1.4334016e+02  4.3839958e+00  3.0584561e-02  |  2.5874438e-01  4.5968098e-02\n",
      "  41  |   1.6700785e+01  |  1.3945811e+02  3.8820551e+00  2.7836712e-02  |  2.4716399e-01  4.5102611e-02\n",
      "  42  |   1.6494250e+01  |  1.3603014e+02  3.4279674e+00  2.5200058e-02  |  2.3537332e-01  4.4068864e-02\n",
      "  43  |   1.6307287e+01  |  1.3296380e+02  3.0663394e+00  2.3061461e-02  |  2.2477362e-01  4.3133095e-02\n",
      "  44  |   1.6138774e+01  |  1.3023002e+02  2.7337796e+00  2.0991931e-02  |  2.1341729e-01  4.1929980e-02\n",
      "  45  |   1.5985038e+01  |  1.2776072e+02  2.4693010e+00  1.9327544e-02  |  2.0467185e-01  4.1127397e-02\n",
      "  46  |   1.5846490e+01  |  1.2555562e+02  2.2050957e+00  1.7562700e-02  |  1.9520272e-01  4.0076493e-02\n",
      "  47  |   1.5719650e+01  |  1.2355370e+02  2.0019262e+00  1.6202884e-02  |  1.8729390e-01  3.9248105e-02\n",
      "  48  |   1.5603399e+01  |  1.2173303e+02  1.8206675e+00  1.4956233e-02  |  1.8002465e-01  3.8466528e-02\n",
      "  49  |   1.5496260e+01  |  1.2006704e+02  1.6659896e+00  1.3875495e-02  |  1.7365914e-01  3.7798152e-02\n",
      "  50  |   1.5397205e+01  |  1.1853697e+02  1.5300739e+00  1.2907990e-02  |  1.6770973e-01  3.7146488e-02\n",
      "  51  |   1.5305714e+01  |  1.1713244e+02  1.4045241e+00  1.1990906e-02  |  1.6163167e-01  3.6394768e-02\n",
      "  52  |   1.5220822e+01  |  1.1583670e+02  1.2957365e+00  1.1185889e-02  |  1.5628907e-01  3.5740588e-02\n",
      "  53  |   1.5141891e+01  |  1.1463842e+02  1.1982802e+00  1.0452692e-02  |  1.5149241e-01  3.5148930e-02\n",
      "  54  |   1.5069404e+01  |  1.1354346e+02  1.0949605e+00  9.6435362e-03  |  1.4537765e-01  3.4188291e-02\n",
      "  55  |   1.5002109e+01  |  1.1253164e+02  1.0118256e+00  8.9914767e-03  |  1.4090703e-01  3.3554462e-02\n",
      "  56  |   1.4940241e+01  |  1.1160541e+02  9.2623213e-01  8.2991691e-03  |  1.3588993e-01  3.2736148e-02\n",
      "  57  |   1.4883275e+01  |  1.1075593e+02  8.4947423e-01  7.6697854e-03  |  1.3073134e-01  3.1830265e-02\n",
      "  58  |   1.4830898e+01  |  1.0997776e+02  7.7816725e-01  7.0756780e-03  |  1.2558487e-01  3.0876717e-02\n",
      "  59  |   1.4782648e+01  |  1.0926335e+02  7.1441743e-01  6.5384912e-03  |  1.2077051e-01  2.9958501e-02\n",
      "  60  |   1.4737956e+01  |  1.0860367e+02  6.5967910e-01  6.0741880e-03  |  1.1661282e-01  2.9162100e-02\n",
      "  61  |   1.4696229e+01  |  1.0798958e+02  6.1408796e-01  5.6865482e-03  |  1.1335514e-01  2.8555502e-02\n",
      "  62  |   1.4657358e+01  |  1.0741908e+02  5.7050512e-01  5.3110225e-03  |  1.1006847e-01  2.7910049e-02\n",
      "  63  |   1.4621116e+01  |  1.0688852e+02  5.3055493e-01  4.9636287e-03  |  1.0661534e-01  2.7192819e-02\n",
      "  64  |   1.4587354e+01  |  1.0639544e+02  4.9307530e-01  4.6343648e-03  |  1.0342456e-01  2.6515551e-02\n",
      "  65  |   1.4555733e+01  |  1.0593468e+02  4.6076775e-01  4.3495459e-03  |  1.0078199e-01  2.5955105e-02\n",
      "  66  |   1.4526105e+01  |  1.0550387e+02  4.3080852e-01  4.0833434e-03  |  9.8530871e-02  2.5474681e-02\n",
      "  67  |   1.4498223e+01  |  1.0509924e+02  4.0462993e-01  3.8499796e-03  |  9.5588841e-02  2.4796359e-02\n",
      "  68  |   1.4472007e+01  |  1.0471949e+02  3.7975101e-01  3.6263642e-03  |  9.3219125e-02  2.4248999e-02\n",
      "  69  |   1.4447043e+01  |  1.0435852e+02  3.6096775e-01  3.4589198e-03  |  9.1563523e-02  2.3872335e-02\n",
      "  70  |   1.4423548e+01  |  1.0401936e+02  3.3915825e-01  3.2605300e-03  |  8.9095442e-02  2.3270112e-02\n",
      "  71  |   1.4401242e+01  |  1.0369788e+02  3.2147717e-01  3.1001324e-03  |  8.6683730e-02  2.2669982e-02\n",
      "  72  |   1.4380034e+01  |  1.0339269e+02  3.0519339e-01  2.9517888e-03  |  8.5039739e-02  2.2259636e-02\n",
      "  73  |   1.4359795e+01  |  1.0310186e+02  2.9083313e-01  2.8208331e-03  |  8.3497088e-02  2.1866101e-02\n",
      "  74  |   1.4340406e+01  |  1.0282362e+02  2.7823843e-01  2.7059778e-03  |  8.2185526e-02  2.1524285e-02\n",
      "  75  |   1.4322192e+01  |  1.0256260e+02  2.6102330e-01  2.5450145e-03  |  8.0254916e-02  2.1012451e-02\n",
      "  76  |   1.4305011e+01  |  1.0231668e+02  2.4591970e-01  2.4035153e-03  |  7.8334367e-02  2.0496465e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  77  |   1.4288861e+01  |  1.0208577e+02  2.3090673e-01  2.2618895e-03  |  7.5634222e-02  1.9771026e-02\n",
      "  78  |   1.4273474e+01  |  1.0186603e+02  2.1974143e-01  2.1571610e-03  |  7.3221637e-02  1.9116671e-02\n",
      "  79  |   1.4258830e+01  |  1.0165712e+02  2.0891089e-01  2.0550543e-03  |  7.1359849e-02  1.8602832e-02\n",
      "  80  |   1.4244875e+01  |  1.0145823e+02  1.9889101e-01  1.9603241e-03  |  6.8506808e-02  1.7828408e-02\n",
      "  81  |   1.4231490e+01  |  1.0126765e+02  1.9057214e-01  1.8818659e-03  |  6.6989688e-02  1.7400177e-02\n",
      "  82  |   1.4218658e+01  |  1.0108511e+02  1.8253987e-01  1.8058036e-03  |  6.5894478e-02  1.7079738e-02\n",
      "  83  |   1.4206320e+01  |  1.0090977e+02  1.7534665e-01  1.7376579e-03  |  6.4844387e-02  1.6769337e-02\n",
      "  84  |   1.4194384e+01  |  1.0074028e+02  1.6949227e-01  1.6824678e-03  |  6.3923882e-02  1.6491009e-02\n",
      "  85  |   1.4182930e+01  |  1.0057775e+02  1.6252881e-01  1.6159520e-03  |  6.3048850e-02  1.6223140e-02\n",
      "  86  |   1.4171863e+01  |  1.0042085e+02  1.5689595e-01  1.5623842e-03  |  6.2133255e-02  1.5943821e-02\n",
      "  87  |   1.4161177e+01  |  1.0026946e+02  1.5139013e-01  1.5098329e-03  |  6.1257649e-02  1.5673971e-02\n",
      "  88  |   1.4150876e+01  |  1.0012364e+02  1.4582025e-01  1.4564018e-03  |  6.0524777e-02  1.5439945e-02\n",
      "  89  |   1.4140874e+01  |  9.9982163e+01  1.4147694e-01  1.4150218e-03  |  5.9841754e-02  1.5217976e-02\n",
      "  90  |   1.4131401e+01  |  9.9848245e+01  1.3391836e-01  1.3412190e-03  |  5.8736236e-02  1.4888414e-02\n",
      "  91  |   1.4122256e+01  |  9.9719061e+01  1.2918355e-01  1.2954750e-03  |  5.7657511e-02  1.4566082e-02\n",
      "  92  |   1.4113524e+01  |  9.9595779e+01  1.2328202e-01  1.2378237e-03  |  5.6379353e-02  1.4194202e-02\n",
      "  93  |   1.4105098e+01  |  9.9476895e+01  1.1888427e-01  1.1950943e-03  |  5.5636712e-02  1.3957941e-02\n",
      "  94  |   1.4096974e+01  |  9.9362342e+01  1.1455319e-01  1.1528834e-03  |  5.4952033e-02  1.3736683e-02\n",
      "  95  |   1.4089056e+01  |  9.9250756e+01  1.1158647e-01  1.1242884e-03  |  5.4363259e-02  1.3539865e-02\n",
      "  96  |   1.4081534e+01  |  9.9144806e+01  1.0594923e-01  1.0686311e-03  |  5.3443056e-02  1.3261316e-02\n",
      "  97  |   1.4074357e+01  |  9.9043756e+01  1.0105024e-01  1.0202586e-03  |  5.2819706e-02  1.3057435e-02\n",
      "  98  |   1.4067378e+01  |  9.8945560e+01  9.8196176e-02  9.9242630e-04  |  5.2240667e-02  1.2865307e-02\n",
      "< Stopping criterion: Relative tolerance on the objective >\n",
      "   [ 00h 00m 07s ]\n"
     ]
    }
   ],
   "source": [
    "mit.fit()\n",
    "## mit.fit(tol_fun = 1e-7, max_iter = 100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Saving results to \"Results_VolumeFractions/*\":\n",
      "\t* configuration and results:\n",
      "\t\t- pickle...  [ OK ]\n",
      "\t\t- txt...  [ OK ]\n",
      "\t* fitting errors:\n",
      "\t\t- RMSE...  [ 0.075 +/- 0.223 ]\n",
      "\t\t- NRMSE... [ 0.018 +/- 0.113 ]\n",
      "\t* voxelwise contributions:\n",
      "\t\t- intra-axonal [ OK ]\n",
      "\t\t- extra-axonal [ OK ]\n",
      "\t\t- isotropic    [ OK ]\n",
      "   [ 0.6 seconds ]\n"
     ]
    }
   ],
   "source": [
    "mit.save_results(save_coeff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_file = os.path.join(path_commit,'dictionary_TRK_fibers.trk')\n",
    "fib_tmp,trk_hdr_tmp=nib.trackvis.read(trk_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate tractography after applying COMMIT with weight > 0, and get fib_after,hdr_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/zhiwei/Desktop/semester-projects/results_script1/COMMIT/Results_VolumeFractions/xic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = f.read().splitlines()\n",
    "data = map(eval,data)\n",
    "j=0\n",
    "for items in range(len(fib_tmp)-1,-1,-1):\n",
    "    if data[j] == 0:\n",
    "        del fib_tmp[items]\n",
    "    j=j+1\n",
    "nib.trackvis.write('fibers_after.trk',fib_tmp,trk_hdr_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_after,hdr_after=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/fibers_after.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD = 'TractConverter.py -i fibers_after.trk -o fibers_after.tck -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap fibers_after.tck syn_CLARITY_after.nii.gz -vox 0.015'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample fibers(before/after) to the original one, take mean distance and std as measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample the fibers and get tracks_before, tracks_after, tracks_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.metrics import downsample\n",
    "import random\n",
    "tracks_after = [downsample(fib_after[i][0],7) for i in range(len(fib_after))]\n",
    "tracks_original = [downsample(fib_original[i][0],7) for i in range(len(fib_original))]\n",
    "## generate a random list to get equal number of fibers from fib before COMMIT\n",
    "list = range(len(fib_before))\n",
    "slice1 = random.sample(list, len(fib_after))\n",
    "tracks_before1 = [downsample(fib_before[i][0],7) for i in slice1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.bundles import bundles_distances_mdf\n",
    "DM_before1 = bundles_distances_mdf(tracks_before1, tracks_original)\n",
    "minD_before1 = [min(DM_before1[i,:]) for i in range(len(DM_before1))]\n",
    "DM_after = bundles_distances_mdf(tracks_after, tracks_original)\n",
    "minD_after = [min(DM_after[i,:]) for i in range(len(DM_after))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare tracks_after and tracks_before with tracks_original with mean distance and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanD_before= np.mean(minD_before1)\n",
    "stdD_before= np.std(minD_before1)\n",
    "\n",
    "meanD_after= np.mean(minD_after)\n",
    "stdD_after= np.std(minD_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1909169839439658"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanD_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1910786749077243"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanD_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meanD_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare on a voxel level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original resolution -- 0.015mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in range(len(fib_before)-1,-1,-1):\n",
    "    if items not in slice1:\n",
    "        del fib_before[items]\n",
    "    j=j+1\n",
    "nib.trackvis.write('fibers_before.trk',fib_before,hdr_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_before,hdr_before=nib.trackvis.read('/home/zhiwei/Desktop/semester-projects/results_script1/fibers_before.trk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD = 'TractConverter.py -i fibers_before.trk -o fibers_before.tck -a fsltensor_ftrial_FA.nii.gz'\n",
    "subprocess.call(CMD,shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap fibers_before.tck syn_CLARITY_random.nii.gz -vox 0.015' \n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = nib.load('syn_CLARITY.nii.gz')\n",
    "data_before = nib.load('syn_CLARITY_random.nii.gz')\n",
    "data_after = nib.load('syn_CLARITY_after.nii.gz')\n",
    "## normalization\n",
    "sum_original = sum(sum(sum(data_original.get_fdata())))\n",
    "sum_before = sum(sum(sum(data_before.get_fdata())))\n",
    "sum_after = sum(sum(sum(data_after.get_fdata())))\n",
    "volume_original = data_original.get_fdata()/sum_original\n",
    "volume_before = data_before.get_fdata()/sum_before\n",
    "volume_after = data_after.get_fdata()/sum_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_error_before = compClarity(volume_before, volume_original)\n",
    "square_error_after = compClarity(volume_after, volume_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change the resolution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resolution based on mean distance after COMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap origin0.015.tck syn_CLARITY_COMMIT_res.nii.gz -vox 0.193' \n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap fibers_after.tck syn_CLARITY_after_COMMIT_res.nii.gz -vox 0.193'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD='tckmap fibers_before.tck syn_CLARITY_random_COMMIT_res.nii.gz -vox 0.193'\n",
    "subprocess.call(CMD, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original_COMMIT_res = nib.load('syn_CLARITY_COMMIT_res.nii.gz')\n",
    "data_before_COMMIT_res = nib.load('syn_CLARITY_random_COMMIT_res.nii.gz')\n",
    "data_after_COMMIT_res = nib.load('syn_CLARITY_after_COMMIT_res.nii.gz')\n",
    "## normalization\n",
    "sum_original_COMMIT_res = sum(sum(sum(data_original_COMMIT_res.get_fdata())))\n",
    "sum_before_COMMIT_res = sum(sum(sum(data_before_COMMIT_res.get_fdata())))\n",
    "sum_after_COMMIT_res = sum(sum(sum(data_after_COMMIT_res.get_fdata())))\n",
    "volume_original_COMMIT_res = data_original_COMMIT_res.get_fdata()/sum_original_COMMIT_res\n",
    "volume_before_COMMIT_res = data_before_COMMIT_res.get_fdata()/sum_before_COMMIT_res\n",
    "volume_after_COMMIT_res = data_after_COMMIT_res.get_fdata()/sum_after_COMMIT_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_error_before_COMMIT_res = compClarity(volume_before_COMMIT_res, volume_original_COMMIT_res)\n",
    "square_error_after_COMMIT_res = compClarity(volume_after_COMMIT_res, volume_original_COMMIT_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare on a voxel level - binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original resolution -- 0.015mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(volume):\n",
    "    volume_prime = np.zeros([len(volume),len(volume[1]),len(volume[1][1])])\n",
    "    for x in range(len(volume)):\n",
    "        for y in range(len(volume[1])):\n",
    "            for z in range(len(volume[1][1])):\n",
    "                if volume[x,y,z]!=0:\n",
    "                    volume_prime[x,y,z]=1\n",
    "    return volume_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume_Original = binarize(volume_original)\n",
    "Volume_Before = binarize(volume_before)\n",
    "Volume_After = binarize(volume_after)\n",
    "error_before = compClarity(Volume_Before, Volume_Original)\n",
    "error_after = compClarity(Volume_After, Volume_Original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change the resolution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMIT resolution 0.186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume_Original_COMMIT_res = binarize(volume_original_COMMIT_res)\n",
    "Volume_Before_COMMIT_res = binarize(volume_before_COMMIT_res)\n",
    "Volume_After_COMMIT_res = binarize(volume_after_COMMIT_res)\n",
    "error_before_COMMIT_res = compClarity(Volume_Before_COMMIT_res, Volume_Original_COMMIT_res)\n",
    "error_after_COMMIT_res = compClarity(Volume_After_COMMIT_res, Volume_Original_COMMIT_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhiwei/Desktop/semester-projects\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('group: Nboffibers_before: ' + str(number))\n",
    "f.write('         Nboffibers_after: ' + str(len(fib_after)))\n",
    "f.write('\\n\\ncompare tractography on a tract level:')\n",
    "#f.write('\\n1. mean distance before COMMIT:  ' + str(meanD_before1))\n",
    "#f.write('\\n   STD before COMMIT:            ' + str(stdD_before1))\n",
    "#f.write('\\n2. mean distance before COMMIT:  ' + str(meanD_before2))\n",
    "#f.write('\\n   STD before COMMIT:            ' + str(stdD_before2))\n",
    "#f.write('\\n3. mean distance before COMMIT:  ' + str(meanD_before3))\n",
    "#f.write('\\n   STD before COMMIT:            ' + str(stdD_before3))\n",
    "#f.write('\\n')\n",
    "    \n",
    "f.write('\\n2. mean distance random:    ' + str(meanD_before))\n",
    "f.write('\\n   STD random:              ' + str(stdD_before)) \n",
    "\n",
    "f.write('\\n1. mean distance COMMIT:     ' + str(meanD_after))\n",
    "f.write('\\n   STD COMMIT:               ' + str(stdD_after)) \n",
    "\n",
    "f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level - BINARIZATION:')\n",
    "f.write('\\nerror random: ' + str(error_before))\n",
    "f.write('\\nerror COMMIT: ' + str(error_after)) \n",
    "f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level - non-BINARIZATION:')\n",
    "f.write('\\nsquare error random: ' + str(square_error_before))\n",
    "f.write('\\nsquare error COMMIT: ' + str(square_error_after)) \n",
    "f.write('\\n\\n\\n\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level_COMMIT_res - BINARIZATION:')\n",
    "f.write('\\nerror random: ' + str(error_before_COMMIT_res))\n",
    "f.write('\\nerror COMMIT: ' + str(error_after_COMMIT_res)) \n",
    "f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('meanD_std3000.txt','a')\n",
    "f.write('\\n')\n",
    "f.write('compare tractography on a voxel level_COMMIT_res- non-BINARIZATION:')\n",
    "f.write('\\nsquare error random: ' + str(square_error_before_COMMIT_res))\n",
    "f.write('\\nsquare error COMMIT: ' + str(square_error_after_COMMIT_res)) \n",
    "f.write('\\n\\n\\n\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
